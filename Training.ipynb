{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Network\n",
    "\n",
    "In this notebook, we will train the CNN-RNN model for Image captioning\n",
    "\n",
    "CNN [ResNet](https://arxiv.org/pdf/1512.03385.pdf) model is used for feature extraction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shahabuddin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import math\n",
    "from data_loader import get_loader\n",
    "from data_loader_val import get_loader as val_get_loader\n",
    "from pycocotools.coco import COCO\n",
    "from torchvision import transforms\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from nlp_utils import clean_sentence, bleu_score\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['annotations', 'images']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset dir path\n",
    "cocoapi_dir = r\"../cocoapi/\"\n",
    "\n",
    "import os\n",
    "folders = [folder for folder in os.listdir(\"../cocoapi/\")]\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128  # batch size\n",
    "vocab_threshold = 5  # minimum word count threshold\n",
    "vocab_from_file = True  # if True, load existing vocab file\n",
    "embed_size = 256  # dimensionality of image and word embeddings\n",
    "hidden_size = 512  # number of features in hidden state of the RNN decoder\n",
    "num_epochs = 3  # number of training epochs\n",
    "save_every = 1  # determines frequency of saving model weights\n",
    "print_every = 20  # determines window for printing average loss\n",
    "log_file = \"training_log.txt\"  # name of file with saved training loss and perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose(\n",
    "    [\n",
    "        # smaller edge of image resized to 256\n",
    "        transforms.Resize(256),\n",
    "        # get 224x224 crop from random location\n",
    "        transforms.RandomCrop(224),\n",
    "        # horizontally flip image with probability=0.5\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        # convert the PIL Image to a tensor\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            (0.485, 0.456, 0.406),  # normalize image for pre-trained model\n",
    "            (0.229, 0.224, 0.225),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully loaded from vocab.pkl file!\n",
      "loading annotations into memory...\n",
      "Done (t=3.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Obtaining caption lengths...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 591753/591753 [01:26<00:00, 6872.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Build data loader.\n",
    "data_loader = get_loader(\n",
    "    transform=transform_train,\n",
    "    mode=\"train\",\n",
    "    batch_size=batch_size,\n",
    "    vocab_threshold=vocab_threshold,\n",
    "    vocab_from_file=vocab_from_file,\n",
    "    cocoapi_loc=cocoapi_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Encoder and RNN Decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.models import ResNet50_Weights\n",
    "\n",
    "\n",
    "# ----------- Encoder ------------\n",
    "class EncoderCNN(nn.Module):\n",
    "    def __init__(self, embed_size):\n",
    "        super(EncoderCNN, self).__init__()\n",
    "        \n",
    "        #resnet = models.resnet50(pretrained=True)\n",
    "        resnet = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n",
    "        \n",
    "        # disable learning for parameters\n",
    "        for param in resnet.parameters():\n",
    "            param.requires_grad_(False)\n",
    "\n",
    "        modules = list(resnet.children())[:-1]\n",
    "        self.resnet = nn.Sequential(*modules)\n",
    "        self.embed = nn.Linear(resnet.fc.in_features, embed_size)\n",
    "\n",
    "    def forward(self, images):\n",
    "        features = self.resnet(images)\n",
    "        features = features.view(features.size(0), -1)\n",
    "        features = self.embed(features)\n",
    "        return features\n",
    "\n",
    "\n",
    "# --------- Decoder ----------\n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size, num_layers=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embed_size: final embedding size of the CNN encoder\n",
    "            hidden_size: hidden size of the LSTM\n",
    "            vocab_size: size of the vocabulary\n",
    "            num_layers: number of layers of the LSTM\n",
    "        \"\"\"\n",
    "        super(DecoderRNN, self).__init__()\n",
    "\n",
    "        # Assigning hidden dimension\n",
    "        self.hidden_dim = hidden_size\n",
    "        # Map each word index to a dense word embedding tensor of embed_size\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        # Creating LSTM layer\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        # Initializing linear to apply at last of RNN layer for further prediction\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "        # Initializing values for hidden and cell state\n",
    "        self.hidden = (torch.zeros(1, 1, hidden_size), torch.zeros(1, 1, hidden_size))\n",
    "\n",
    "    def forward(self, features, captions):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            features: features tensor. shape is (bs, embed_size)\n",
    "            captions: captions tensor. shape is (bs, cap_length)\n",
    "        Returns:\n",
    "            outputs: scores of the linear layer\n",
    "\n",
    "        \"\"\"\n",
    "        # remove <end> token from captions and embed captions\n",
    "        cap_embedding = self.embed(\n",
    "            captions[:, :-1]\n",
    "        )  # (bs, cap_length) -> (bs, cap_length-1, embed_size)\n",
    "\n",
    "        embeddings = torch.cat((features.unsqueeze(dim=1), cap_embedding), dim=1)\n",
    "\n",
    "        #  getting output i.e. score and hidden layer.\n",
    "        # first value: all the hidden states throughout the sequence. second value: the most recent hidden state\n",
    "        lstm_out, self.hidden = self.lstm(\n",
    "            embeddings\n",
    "        )  # (bs, cap_length, hidden_size), (1, bs, hidden_size)\n",
    "        outputs = self.linear(lstm_out)  # (bs, cap_length, vocab_size)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def sample(self, inputs, states=None, max_len=20):\n",
    "        \"\"\"\n",
    "        accepts pre-processed image tensor (inputs) and returns predicted\n",
    "        sentence (list of tensor ids of length max_len)\n",
    "        Args:\n",
    "            inputs: shape is (1, 1, embed_size)\n",
    "            states: initial hidden state of the LSTM\n",
    "            max_len: maximum length of the predicted sentence\n",
    "\n",
    "        Returns:\n",
    "            res: list of predicted words indices\n",
    "        \"\"\"\n",
    "        res = []\n",
    "\n",
    "        # Now we feed the LSTM output and hidden states back into itself to get the caption\n",
    "        for i in range(max_len):\n",
    "            lstm_out, states = self.lstm(\n",
    "                inputs, states\n",
    "            )  # lstm_out: (1, 1, hidden_size)\n",
    "            outputs = self.linear(lstm_out.squeeze(dim=1))  # outputs: (1, vocab_size)\n",
    "            _, predicted_idx = outputs.max(dim=1)  # predicted: (1, 1)\n",
    "            res.append(predicted_idx.item())\n",
    "            # if the predicted idx is the stop index, the loop stops\n",
    "            if predicted_idx == 1:\n",
    "                break\n",
    "            inputs = self.embed(predicted_idx)  # inputs: (1, embed_size)\n",
    "            # prepare input for next iteration\n",
    "            inputs = inputs.unsqueeze(1)  # inputs: (1, 1, embed_size)\n",
    "\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size is :  11543\n"
     ]
    }
   ],
   "source": [
    "# The size of the vocabulary.\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "print(\"vocab size is : \",vocab_size)\n",
    "\n",
    "# Initializing the encoder and decoder\n",
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "\n",
    "# Move models to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# Defining the loss function\n",
    "criterion = (\n",
    "    nn.CrossEntropyLoss().cuda() if torch.cuda.is_available() else nn.CrossEntropyLoss()\n",
    ")\n",
    "\n",
    "# Specifying the learnable parameters of the mode\n",
    "params = list(decoder.parameters()) + list(encoder.embed.parameters())\n",
    "\n",
    "# Defining the optimize\n",
    "optimizer = torch.optim.Adam(params, lr=0.001)\n",
    "\n",
    "# Set the total number of training steps per epoc\n",
    "total_step = math.ceil(len(data_loader.dataset) / data_loader.batch_sampler.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4624\n"
     ]
    }
   ],
   "source": [
    "print(total_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [20/4624], Loss: 4.8909, Perplexity: 133.0795\n",
      "Epoch [1/3], Step [40/4624], Loss: 4.3491, Perplexity: 77.4075\n",
      "Epoch [1/3], Step [60/4624], Loss: 4.1604, Perplexity: 64.0983\n",
      "Epoch [1/3], Step [80/4624], Loss: 4.1200, Perplexity: 61.5567\n",
      "Epoch [1/3], Step [100/4624], Loss: 3.8808, Perplexity: 48.4608\n",
      "Epoch [1/3], Step [120/4624], Loss: 3.5545, Perplexity: 34.9715\n",
      "Epoch [1/3], Step [140/4624], Loss: 3.5900, Perplexity: 36.2346\n",
      "Epoch [1/3], Step [160/4624], Loss: 3.6579, Perplexity: 38.7811\n",
      "Epoch [1/3], Step [180/4624], Loss: 3.3274, Perplexity: 27.8669\n",
      "Epoch [1/3], Step [200/4624], Loss: 3.9791, Perplexity: 53.4671\n",
      "Epoch [1/3], Step [220/4624], Loss: 3.3535, Perplexity: 28.6031\n",
      "Epoch [1/3], Step [240/4624], Loss: 3.4932, Perplexity: 32.8923\n",
      "Epoch [1/3], Step [260/4624], Loss: 3.5685, Perplexity: 35.4631\n",
      "Epoch [1/3], Step [280/4624], Loss: 3.4542, Perplexity: 31.6335\n",
      "Epoch [1/3], Step [300/4624], Loss: 3.5838, Perplexity: 36.0106\n",
      "Epoch [1/3], Step [320/4624], Loss: 3.2782, Perplexity: 26.5293\n",
      "Epoch [1/3], Step [340/4624], Loss: 3.8071, Perplexity: 45.0186\n",
      "Epoch [1/3], Step [360/4624], Loss: 3.3743, Perplexity: 29.2027\n",
      "Epoch [1/3], Step [380/4624], Loss: 3.2715, Perplexity: 26.3497\n",
      "Epoch [1/3], Step [400/4624], Loss: 3.3264, Perplexity: 27.8391\n",
      "Epoch [1/3], Step [420/4624], Loss: 3.5675, Perplexity: 35.4264\n",
      "Epoch [1/3], Step [440/4624], Loss: 3.2560, Perplexity: 25.9449\n",
      "Epoch [1/3], Step [460/4624], Loss: 2.9885, Perplexity: 19.8562\n",
      "Epoch [1/3], Step [480/4624], Loss: 3.2983, Perplexity: 27.0664\n",
      "Epoch [1/3], Step [500/4624], Loss: 2.9427, Perplexity: 18.9664\n",
      "Epoch [1/3], Step [520/4624], Loss: 3.2065, Perplexity: 24.6915\n",
      "Epoch [1/3], Step [540/4624], Loss: 3.0979, Perplexity: 22.1514\n",
      "Epoch [1/3], Step [560/4624], Loss: 2.9104, Perplexity: 18.3641\n",
      "Epoch [1/3], Step [580/4624], Loss: 3.0886, Perplexity: 21.9456\n",
      "Epoch [1/3], Step [600/4624], Loss: 3.2732, Perplexity: 26.3946\n",
      "Epoch [1/3], Step [620/4624], Loss: 3.1398, Perplexity: 23.1004\n",
      "Epoch [1/3], Step [640/4624], Loss: 2.8623, Perplexity: 17.5024\n",
      "Epoch [1/3], Step [660/4624], Loss: 2.8401, Perplexity: 17.1179\n",
      "Epoch [1/3], Step [680/4624], Loss: 3.0286, Perplexity: 20.6692\n",
      "Epoch [1/3], Step [700/4624], Loss: 2.7841, Perplexity: 16.1859\n",
      "Epoch [1/3], Step [720/4624], Loss: 3.2031, Perplexity: 24.6087\n",
      "Epoch [1/3], Step [740/4624], Loss: 2.8782, Perplexity: 17.7827\n",
      "Epoch [1/3], Step [760/4624], Loss: 2.8493, Perplexity: 17.2756\n",
      "Epoch [1/3], Step [780/4624], Loss: 2.7025, Perplexity: 14.9169\n",
      "Epoch [1/3], Step [800/4624], Loss: 2.7508, Perplexity: 15.6547\n",
      "Epoch [1/3], Step [820/4624], Loss: 3.0094, Perplexity: 20.2753\n",
      "Epoch [1/3], Step [840/4624], Loss: 3.5074, Perplexity: 33.3627\n",
      "Epoch [1/3], Step [860/4624], Loss: 2.8296, Perplexity: 16.9390\n",
      "Epoch [1/3], Step [880/4624], Loss: 2.6657, Perplexity: 14.3784\n",
      "Epoch [1/3], Step [900/4624], Loss: 2.7221, Perplexity: 15.2123\n",
      "Epoch [1/3], Step [920/4624], Loss: 2.7660, Perplexity: 15.8951\n",
      "Epoch [1/3], Step [940/4624], Loss: 2.7980, Perplexity: 16.4119\n",
      "Epoch [1/3], Step [960/4624], Loss: 2.5827, Perplexity: 13.2331\n",
      "Epoch [1/3], Step [980/4624], Loss: 2.7143, Perplexity: 15.0942\n",
      "Epoch [1/3], Step [1000/4624], Loss: 2.5251, Perplexity: 12.4916\n",
      "Epoch [1/3], Step [1020/4624], Loss: 2.6070, Perplexity: 13.5590\n",
      "Epoch [1/3], Step [1040/4624], Loss: 2.7831, Perplexity: 16.1684\n",
      "Epoch [1/3], Step [1060/4624], Loss: 2.9809, Perplexity: 19.7057\n",
      "Epoch [1/3], Step [1080/4624], Loss: 2.7183, Perplexity: 15.1542\n",
      "Epoch [1/3], Step [1100/4624], Loss: 2.7245, Perplexity: 15.2481\n",
      "Epoch [1/3], Step [1120/4624], Loss: 2.6080, Perplexity: 13.5723\n",
      "Epoch [1/3], Step [1140/4624], Loss: 2.8089, Perplexity: 16.5924\n",
      "Epoch [1/3], Step [1160/4624], Loss: 2.6858, Perplexity: 14.6701\n",
      "Epoch [1/3], Step [1180/4624], Loss: 2.6380, Perplexity: 13.9850\n",
      "Epoch [1/3], Step [1200/4624], Loss: 2.6541, Perplexity: 14.2119\n",
      "Epoch [1/3], Step [1220/4624], Loss: 2.4521, Perplexity: 11.6126\n",
      "Epoch [1/3], Step [1240/4624], Loss: 3.0372, Perplexity: 20.8474\n",
      "Epoch [1/3], Step [1260/4624], Loss: 2.4659, Perplexity: 11.7735\n",
      "Epoch [1/3], Step [1280/4624], Loss: 2.8579, Perplexity: 17.4252\n",
      "Epoch [1/3], Step [1300/4624], Loss: 2.6132, Perplexity: 13.6431\n",
      "Epoch [1/3], Step [1320/4624], Loss: 2.3331, Perplexity: 10.3096\n",
      "Epoch [1/3], Step [1340/4624], Loss: 2.4207, Perplexity: 11.2543\n",
      "Epoch [1/3], Step [1360/4624], Loss: 2.4153, Perplexity: 11.1930\n",
      "Epoch [1/3], Step [1380/4624], Loss: 2.8093, Perplexity: 16.5991\n",
      "Epoch [1/3], Step [1400/4624], Loss: 2.3459, Perplexity: 10.4429\n",
      "Epoch [1/3], Step [1420/4624], Loss: 2.5347, Perplexity: 12.6132\n",
      "Epoch [1/3], Step [1440/4624], Loss: 2.5078, Perplexity: 12.2781\n",
      "Epoch [1/3], Step [1460/4624], Loss: 2.4187, Perplexity: 11.2314\n",
      "Epoch [1/3], Step [1480/4624], Loss: 2.5109, Perplexity: 12.3162\n",
      "Epoch [1/3], Step [1500/4624], Loss: 2.4787, Perplexity: 11.9260\n",
      "Epoch [1/3], Step [1520/4624], Loss: 2.3498, Perplexity: 10.4832\n",
      "Epoch [1/3], Step [1540/4624], Loss: 2.3277, Perplexity: 10.2547\n",
      "Epoch [1/3], Step [1560/4624], Loss: 2.5615, Perplexity: 12.9557\n",
      "Epoch [1/3], Step [1580/4624], Loss: 2.5650, Perplexity: 13.0008\n",
      "Epoch [1/3], Step [1600/4624], Loss: 2.5502, Perplexity: 12.8097\n",
      "Epoch [1/3], Step [1620/4624], Loss: 2.4430, Perplexity: 11.5075\n",
      "Epoch [1/3], Step [1640/4624], Loss: 2.4373, Perplexity: 11.4419\n",
      "Epoch [1/3], Step [1660/4624], Loss: 2.3565, Perplexity: 10.5535\n",
      "Epoch [1/3], Step [1680/4624], Loss: 2.6370, Perplexity: 13.9715\n",
      "Epoch [1/3], Step [1700/4624], Loss: 2.5617, Perplexity: 12.9578\n",
      "Epoch [1/3], Step [1720/4624], Loss: 2.5321, Perplexity: 12.5801\n",
      "Epoch [1/3], Step [1740/4624], Loss: 2.5469, Perplexity: 12.7680\n",
      "Epoch [1/3], Step [1760/4624], Loss: 2.4418, Perplexity: 11.4937\n",
      "Epoch [1/3], Step [1780/4624], Loss: 2.2434, Perplexity: 9.4254\n",
      "Epoch [1/3], Step [1800/4624], Loss: 2.3820, Perplexity: 10.8264\n",
      "Epoch [1/3], Step [1820/4624], Loss: 2.3856, Perplexity: 10.8658\n",
      "Epoch [1/3], Step [1840/4624], Loss: 2.4150, Perplexity: 11.1896\n",
      "Epoch [1/3], Step [1860/4624], Loss: 2.2986, Perplexity: 9.9598\n",
      "Epoch [1/3], Step [1880/4624], Loss: 2.4961, Perplexity: 12.1352\n",
      "Epoch [1/3], Step [1900/4624], Loss: 2.7702, Perplexity: 15.9617\n",
      "Epoch [1/3], Step [1920/4624], Loss: 2.4283, Perplexity: 11.3393\n",
      "Epoch [1/3], Step [1940/4624], Loss: 2.4268, Perplexity: 11.3222\n",
      "Epoch [1/3], Step [1960/4624], Loss: 2.3684, Perplexity: 10.6798\n",
      "Epoch [1/3], Step [1980/4624], Loss: 3.0553, Perplexity: 21.2276\n",
      "Epoch [1/3], Step [2000/4624], Loss: 2.4898, Perplexity: 12.0589\n",
      "Epoch [1/3], Step [2020/4624], Loss: 2.3026, Perplexity: 10.0006\n",
      "Epoch [1/3], Step [2040/4624], Loss: 2.5455, Perplexity: 12.7497\n",
      "Epoch [1/3], Step [2060/4624], Loss: 2.4265, Perplexity: 11.3192\n",
      "Epoch [1/3], Step [2080/4624], Loss: 2.5753, Perplexity: 13.1350\n",
      "Epoch [1/3], Step [2100/4624], Loss: 2.5507, Perplexity: 12.8166\n",
      "Epoch [1/3], Step [2120/4624], Loss: 2.2952, Perplexity: 9.9267\n",
      "Epoch [1/3], Step [2140/4624], Loss: 2.4370, Perplexity: 11.4384\n",
      "Epoch [1/3], Step [2160/4624], Loss: 2.5147, Perplexity: 12.3630\n",
      "Epoch [1/3], Step [2180/4624], Loss: 2.3767, Perplexity: 10.7692\n",
      "Epoch [1/3], Step [2200/4624], Loss: 2.3967, Perplexity: 10.9865\n",
      "Epoch [1/3], Step [2220/4624], Loss: 2.4374, Perplexity: 11.4432\n",
      "Epoch [1/3], Step [2240/4624], Loss: 2.3876, Perplexity: 10.8869\n",
      "Epoch [1/3], Step [2260/4624], Loss: 2.4485, Perplexity: 11.5713\n",
      "Epoch [1/3], Step [2280/4624], Loss: 2.1834, Perplexity: 8.8766\n",
      "Epoch [1/3], Step [2300/4624], Loss: 2.3227, Perplexity: 10.2031\n",
      "Epoch [1/3], Step [2320/4624], Loss: 2.2350, Perplexity: 9.3468\n",
      "Epoch [1/3], Step [2340/4624], Loss: 2.6145, Perplexity: 13.6603\n",
      "Epoch [1/3], Step [2360/4624], Loss: 2.2112, Perplexity: 9.1270\n",
      "Epoch [1/3], Step [2380/4624], Loss: 2.5097, Perplexity: 12.3017\n",
      "Epoch [1/3], Step [2400/4624], Loss: 2.2717, Perplexity: 9.6960\n",
      "Epoch [1/3], Step [2420/4624], Loss: 2.2137, Perplexity: 9.1500\n",
      "Epoch [1/3], Step [2440/4624], Loss: 2.1545, Perplexity: 8.6239\n",
      "Epoch [1/3], Step [2460/4624], Loss: 2.4136, Perplexity: 11.1744\n",
      "Epoch [1/3], Step [2480/4624], Loss: 2.4185, Perplexity: 11.2289\n",
      "Epoch [1/3], Step [2500/4624], Loss: 2.2069, Perplexity: 9.0876\n",
      "Epoch [1/3], Step [2520/4624], Loss: 2.3034, Perplexity: 10.0078\n",
      "Epoch [1/3], Step [2540/4624], Loss: 2.5081, Perplexity: 12.2813\n",
      "Epoch [1/3], Step [2560/4624], Loss: 2.3156, Perplexity: 10.1312\n",
      "Epoch [1/3], Step [2580/4624], Loss: 2.2345, Perplexity: 9.3420\n",
      "Epoch [1/3], Step [2600/4624], Loss: 2.2624, Perplexity: 9.6061\n",
      "Epoch [1/3], Step [2620/4624], Loss: 2.3254, Perplexity: 10.2310\n",
      "Epoch [1/3], Step [2640/4624], Loss: 2.3713, Perplexity: 10.7117\n",
      "Epoch [1/3], Step [2660/4624], Loss: 2.1592, Perplexity: 8.6640\n",
      "Epoch [1/3], Step [2680/4624], Loss: 2.2780, Perplexity: 9.7571\n",
      "Epoch [1/3], Step [2700/4624], Loss: 2.1686, Perplexity: 8.7463\n",
      "Epoch [1/3], Step [2720/4624], Loss: 2.3781, Perplexity: 10.7840\n",
      "Epoch [1/3], Step [2740/4624], Loss: 2.2712, Perplexity: 9.6906\n",
      "Epoch [1/3], Step [2760/4624], Loss: 2.3640, Perplexity: 10.6338\n",
      "Epoch [1/3], Step [2780/4624], Loss: 2.3999, Perplexity: 11.0226\n",
      "Epoch [1/3], Step [2800/4624], Loss: 2.1566, Perplexity: 8.6421\n",
      "Epoch [1/3], Step [2820/4624], Loss: 2.1915, Perplexity: 8.9489\n",
      "Epoch [1/3], Step [2840/4624], Loss: 2.2086, Perplexity: 9.1032\n",
      "Epoch [1/3], Step [2860/4624], Loss: 2.2220, Perplexity: 9.2256\n",
      "Epoch [1/3], Step [2880/4624], Loss: 2.1644, Perplexity: 8.7094\n",
      "Epoch [1/3], Step [2900/4624], Loss: 2.5687, Perplexity: 13.0482\n",
      "Epoch [1/3], Step [2920/4624], Loss: 2.2183, Perplexity: 9.1917\n",
      "Epoch [1/3], Step [2940/4624], Loss: 2.0774, Perplexity: 7.9836\n",
      "Epoch [1/3], Step [2960/4624], Loss: 2.2492, Perplexity: 9.4804\n",
      "Epoch [1/3], Step [2980/4624], Loss: 2.3488, Perplexity: 10.4725\n",
      "Epoch [1/3], Step [3000/4624], Loss: 2.2054, Perplexity: 9.0741\n",
      "Epoch [1/3], Step [3020/4624], Loss: 2.6268, Perplexity: 13.8298\n",
      "Epoch [1/3], Step [3040/4624], Loss: 2.4922, Perplexity: 12.0877\n",
      "Epoch [1/3], Step [3060/4624], Loss: 2.1771, Perplexity: 8.8205\n",
      "Epoch [1/3], Step [3080/4624], Loss: 2.2326, Perplexity: 9.3240\n",
      "Epoch [1/3], Step [3100/4624], Loss: 2.2435, Perplexity: 9.4264\n",
      "Epoch [1/3], Step [3120/4624], Loss: 2.3455, Perplexity: 10.4384\n",
      "Epoch [1/3], Step [3140/4624], Loss: 2.2274, Perplexity: 9.2755\n",
      "Epoch [1/3], Step [3160/4624], Loss: 2.0329, Perplexity: 7.6362\n",
      "Epoch [1/3], Step [3180/4624], Loss: 2.2733, Perplexity: 9.7119\n",
      "Epoch [1/3], Step [3200/4624], Loss: 2.4928, Perplexity: 12.0948\n",
      "Epoch [1/3], Step [3220/4624], Loss: 2.1812, Perplexity: 8.8572\n",
      "Epoch [1/3], Step [3240/4624], Loss: 2.0861, Perplexity: 8.0532\n",
      "Epoch [1/3], Step [3260/4624], Loss: 2.6139, Perplexity: 13.6520\n",
      "Epoch [1/3], Step [3280/4624], Loss: 2.2994, Perplexity: 9.9681\n",
      "Epoch [1/3], Step [3300/4624], Loss: 2.5519, Perplexity: 12.8316\n",
      "Epoch [1/3], Step [3320/4624], Loss: 2.1300, Perplexity: 8.4152\n",
      "Epoch [1/3], Step [3340/4624], Loss: 2.4306, Perplexity: 11.3659\n",
      "Epoch [1/3], Step [3360/4624], Loss: 2.1997, Perplexity: 9.0225\n",
      "Epoch [1/3], Step [3380/4624], Loss: 2.1792, Perplexity: 8.8390\n",
      "Epoch [1/3], Step [3400/4624], Loss: 2.4613, Perplexity: 11.7195\n",
      "Epoch [1/3], Step [3420/4624], Loss: 2.1708, Perplexity: 8.7650\n",
      "Epoch [1/3], Step [3440/4624], Loss: 2.2018, Perplexity: 9.0408\n",
      "Epoch [1/3], Step [3460/4624], Loss: 2.3286, Perplexity: 10.2634\n",
      "Epoch [1/3], Step [3480/4624], Loss: 2.2593, Perplexity: 9.5764\n",
      "Epoch [1/3], Step [3500/4624], Loss: 2.0448, Perplexity: 7.7280\n",
      "Epoch [1/3], Step [3520/4624], Loss: 2.0834, Perplexity: 8.0316\n",
      "Epoch [1/3], Step [3540/4624], Loss: 2.4501, Perplexity: 11.5892\n",
      "Epoch [1/3], Step [3560/4624], Loss: 2.1991, Perplexity: 9.0170\n",
      "Epoch [1/3], Step [3580/4624], Loss: 2.1848, Perplexity: 8.8888\n",
      "Epoch [1/3], Step [3600/4624], Loss: 2.1450, Perplexity: 8.5422\n",
      "Epoch [1/3], Step [3620/4624], Loss: 2.2317, Perplexity: 9.3160\n",
      "Epoch [1/3], Step [3640/4624], Loss: 2.4911, Perplexity: 12.0750\n",
      "Epoch [1/3], Step [3660/4624], Loss: 2.1274, Perplexity: 8.3933\n",
      "Epoch [1/3], Step [3680/4624], Loss: 2.1094, Perplexity: 8.2431\n",
      "Epoch [1/3], Step [3700/4624], Loss: 2.2506, Perplexity: 9.4930\n",
      "Epoch [1/3], Step [3720/4624], Loss: 2.1086, Perplexity: 8.2364\n",
      "Epoch [1/3], Step [3740/4624], Loss: 2.2188, Perplexity: 9.1964\n",
      "Epoch [1/3], Step [3760/4624], Loss: 2.2387, Perplexity: 9.3811\n",
      "Epoch [1/3], Step [3780/4624], Loss: 2.1010, Perplexity: 8.1745\n",
      "Epoch [1/3], Step [3800/4624], Loss: 2.2700, Perplexity: 9.6794\n",
      "Epoch [1/3], Step [3820/4624], Loss: 2.1006, Perplexity: 8.1709\n",
      "Epoch [1/3], Step [3840/4624], Loss: 2.2091, Perplexity: 9.1076\n",
      "Epoch [1/3], Step [3860/4624], Loss: 2.0666, Perplexity: 7.8981\n",
      "Epoch [1/3], Step [3880/4624], Loss: 2.5140, Perplexity: 12.3542\n",
      "Epoch [1/3], Step [3900/4624], Loss: 2.3092, Perplexity: 10.0666\n",
      "Epoch [1/3], Step [3920/4624], Loss: 2.0126, Perplexity: 7.4824\n",
      "Epoch [1/3], Step [3940/4624], Loss: 2.2474, Perplexity: 9.4631\n",
      "Epoch [1/3], Step [3960/4624], Loss: 2.2510, Perplexity: 9.4968\n",
      "Epoch [1/3], Step [3980/4624], Loss: 2.1504, Perplexity: 8.5881\n",
      "Epoch [1/3], Step [4000/4624], Loss: 2.0633, Perplexity: 7.8721\n",
      "Epoch [1/3], Step [4020/4624], Loss: 2.0952, Perplexity: 8.1274\n",
      "Epoch [1/3], Step [4040/4624], Loss: 2.0264, Perplexity: 7.5867\n",
      "Epoch [1/3], Step [4060/4624], Loss: 2.1850, Perplexity: 8.8911\n",
      "Epoch [1/3], Step [4080/4624], Loss: 2.4849, Perplexity: 11.9999\n",
      "Epoch [1/3], Step [4100/4624], Loss: 2.5285, Perplexity: 12.5343\n",
      "Epoch [1/3], Step [4120/4624], Loss: 2.7969, Perplexity: 16.3938\n",
      "Epoch [1/3], Step [4140/4624], Loss: 2.0233, Perplexity: 7.5632\n",
      "Epoch [1/3], Step [4160/4624], Loss: 2.4242, Perplexity: 11.2932\n",
      "Epoch [1/3], Step [4180/4624], Loss: 2.1025, Perplexity: 8.1863\n",
      "Epoch [1/3], Step [4200/4624], Loss: 2.5798, Perplexity: 13.1951\n",
      "Epoch [1/3], Step [4220/4624], Loss: 2.3676, Perplexity: 10.6721\n",
      "Epoch [1/3], Step [4240/4624], Loss: 2.1885, Perplexity: 8.9214\n",
      "Epoch [1/3], Step [4260/4624], Loss: 2.3778, Perplexity: 10.7816\n",
      "Epoch [1/3], Step [4280/4624], Loss: 2.1504, Perplexity: 8.5884\n",
      "Epoch [1/3], Step [4300/4624], Loss: 2.1641, Perplexity: 8.7067\n",
      "Epoch [1/3], Step [4320/4624], Loss: 2.0718, Perplexity: 7.9394\n",
      "Epoch [1/3], Step [4340/4624], Loss: 2.0572, Perplexity: 7.8242\n",
      "Epoch [1/3], Step [4360/4624], Loss: 2.3305, Perplexity: 10.2827\n",
      "Epoch [1/3], Step [4380/4624], Loss: 2.1039, Perplexity: 8.1984\n",
      "Epoch [1/3], Step [4400/4624], Loss: 2.3347, Perplexity: 10.3268\n",
      "Epoch [1/3], Step [4420/4624], Loss: 2.1287, Perplexity: 8.4037\n",
      "Epoch [1/3], Step [4440/4624], Loss: 2.3243, Perplexity: 10.2193\n",
      "Epoch [1/3], Step [4460/4624], Loss: 2.0796, Perplexity: 8.0015\n",
      "Epoch [1/3], Step [4480/4624], Loss: 2.1174, Perplexity: 8.3094\n",
      "Epoch [1/3], Step [4500/4624], Loss: 2.1043, Perplexity: 8.2016\n",
      "Epoch [1/3], Step [4520/4624], Loss: 2.0962, Perplexity: 8.1349\n",
      "Epoch [1/3], Step [4540/4624], Loss: 2.1761, Perplexity: 8.8117\n",
      "Epoch [1/3], Step [4560/4624], Loss: 2.1618, Perplexity: 8.6871\n",
      "Epoch [1/3], Step [4580/4624], Loss: 2.0451, Perplexity: 7.7297\n",
      "Epoch [1/3], Step [4600/4624], Loss: 2.1409, Perplexity: 8.5072\n",
      "Epoch [1/3], Step [4620/4624], Loss: 2.1252, Perplexity: 8.3743\n",
      "Epoch [2/3], Step [20/4624], Loss: 2.1205, Perplexity: 8.3352\n",
      "Epoch [2/3], Step [40/4624], Loss: 2.2420, Perplexity: 9.4121\n",
      "Epoch [2/3], Step [60/4624], Loss: 2.0895, Perplexity: 8.0813\n",
      "Epoch [2/3], Step [80/4624], Loss: 2.1219, Perplexity: 8.3470\n",
      "Epoch [2/3], Step [100/4624], Loss: 2.4938, Perplexity: 12.1072\n",
      "Epoch [2/3], Step [120/4624], Loss: 2.1293, Perplexity: 8.4094\n",
      "Epoch [2/3], Step [140/4624], Loss: 2.1950, Perplexity: 8.9798\n",
      "Epoch [2/3], Step [160/4624], Loss: 1.9500, Perplexity: 7.0285\n",
      "Epoch [2/3], Step [180/4624], Loss: 2.0376, Perplexity: 7.6723\n",
      "Epoch [2/3], Step [200/4624], Loss: 2.6899, Perplexity: 14.7302\n",
      "Epoch [2/3], Step [220/4624], Loss: 2.1578, Perplexity: 8.6518\n",
      "Epoch [2/3], Step [240/4624], Loss: 2.2179, Perplexity: 9.1880\n",
      "Epoch [2/3], Step [260/4624], Loss: 2.0705, Perplexity: 7.9289\n",
      "Epoch [2/3], Step [280/4624], Loss: 2.4767, Perplexity: 11.9014\n",
      "Epoch [2/3], Step [300/4624], Loss: 2.0744, Perplexity: 7.9594\n",
      "Epoch [2/3], Step [320/4624], Loss: 2.1652, Perplexity: 8.7160\n",
      "Epoch [2/3], Step [340/4624], Loss: 2.0805, Perplexity: 8.0084\n",
      "Epoch [2/3], Step [360/4624], Loss: 2.1816, Perplexity: 8.8604\n",
      "Epoch [2/3], Step [380/4624], Loss: 2.2107, Perplexity: 9.1225\n",
      "Epoch [2/3], Step [400/4624], Loss: 2.2486, Perplexity: 9.4742\n",
      "Epoch [2/3], Step [420/4624], Loss: 2.1193, Perplexity: 8.3255\n",
      "Epoch [2/3], Step [440/4624], Loss: 2.2125, Perplexity: 9.1385\n",
      "Epoch [2/3], Step [460/4624], Loss: 2.1456, Perplexity: 8.5472\n",
      "Epoch [2/3], Step [480/4624], Loss: 2.0709, Perplexity: 7.9323\n",
      "Epoch [2/3], Step [500/4624], Loss: 2.0964, Perplexity: 8.1365\n",
      "Epoch [2/3], Step [520/4624], Loss: 2.0326, Perplexity: 7.6343\n",
      "Epoch [2/3], Step [540/4624], Loss: 2.2833, Perplexity: 9.8090\n",
      "Epoch [2/3], Step [560/4624], Loss: 2.3546, Perplexity: 10.5340\n",
      "Epoch [2/3], Step [580/4624], Loss: 2.0292, Perplexity: 7.6083\n",
      "Epoch [2/3], Step [600/4624], Loss: 2.2341, Perplexity: 9.3377\n",
      "Epoch [2/3], Step [620/4624], Loss: 1.9553, Perplexity: 7.0662\n",
      "Epoch [2/3], Step [640/4624], Loss: 2.2742, Perplexity: 9.7204\n",
      "Epoch [2/3], Step [660/4624], Loss: 2.3024, Perplexity: 9.9978\n",
      "Epoch [2/3], Step [680/4624], Loss: 2.1409, Perplexity: 8.5070\n",
      "Epoch [2/3], Step [700/4624], Loss: 2.7183, Perplexity: 15.1540\n",
      "Epoch [2/3], Step [720/4624], Loss: 2.0737, Perplexity: 7.9540\n",
      "Epoch [2/3], Step [740/4624], Loss: 2.0010, Perplexity: 7.3962\n",
      "Epoch [2/3], Step [760/4624], Loss: 2.1043, Perplexity: 8.2014\n",
      "Epoch [2/3], Step [780/4624], Loss: 2.2197, Perplexity: 9.2046\n",
      "Epoch [2/3], Step [800/4624], Loss: 1.9475, Perplexity: 7.0113\n",
      "Epoch [2/3], Step [820/4624], Loss: 1.9905, Perplexity: 7.3196\n",
      "Epoch [2/3], Step [840/4624], Loss: 2.4745, Perplexity: 11.8763\n",
      "Epoch [2/3], Step [860/4624], Loss: 2.3931, Perplexity: 10.9479\n",
      "Epoch [2/3], Step [880/4624], Loss: 2.0194, Perplexity: 7.5334\n",
      "Epoch [2/3], Step [900/4624], Loss: 2.0773, Perplexity: 7.9829\n",
      "Epoch [2/3], Step [920/4624], Loss: 2.4007, Perplexity: 11.0304\n",
      "Epoch [2/3], Step [940/4624], Loss: 2.2917, Perplexity: 9.8920\n",
      "Epoch [2/3], Step [960/4624], Loss: 2.0180, Perplexity: 7.5236\n",
      "Epoch [2/3], Step [980/4624], Loss: 2.0151, Perplexity: 7.5017\n",
      "Epoch [2/3], Step [1000/4624], Loss: 2.0791, Perplexity: 7.9973\n",
      "Epoch [2/3], Step [1020/4624], Loss: 2.1229, Perplexity: 8.3556\n",
      "Epoch [2/3], Step [1040/4624], Loss: 2.0039, Perplexity: 7.4178\n",
      "Epoch [2/3], Step [1060/4624], Loss: 2.1165, Perplexity: 8.3017\n",
      "Epoch [2/3], Step [1080/4624], Loss: 2.5690, Perplexity: 13.0529\n",
      "Epoch [2/3], Step [1100/4624], Loss: 2.1038, Perplexity: 8.1976\n",
      "Epoch [2/3], Step [1120/4624], Loss: 1.9819, Perplexity: 7.2563\n",
      "Epoch [2/3], Step [1140/4624], Loss: 2.2493, Perplexity: 9.4807\n",
      "Epoch [2/3], Step [1160/4624], Loss: 2.4328, Perplexity: 11.3910\n",
      "Epoch [2/3], Step [1180/4624], Loss: 2.3296, Perplexity: 10.2736\n",
      "Epoch [2/3], Step [1200/4624], Loss: 2.1076, Perplexity: 8.2288\n",
      "Epoch [2/3], Step [1220/4624], Loss: 2.0108, Perplexity: 7.4692\n",
      "Epoch [2/3], Step [1240/4624], Loss: 2.1332, Perplexity: 8.4415\n",
      "Epoch [2/3], Step [1260/4624], Loss: 1.9953, Perplexity: 7.3542\n",
      "Epoch [2/3], Step [1280/4624], Loss: 2.1441, Perplexity: 8.5341\n",
      "Epoch [2/3], Step [1300/4624], Loss: 1.9354, Perplexity: 6.9268\n",
      "Epoch [2/3], Step [1320/4624], Loss: 2.0884, Perplexity: 8.0718\n",
      "Epoch [2/3], Step [1340/4624], Loss: 2.0073, Perplexity: 7.4429\n",
      "Epoch [2/3], Step [1360/4624], Loss: 2.0475, Perplexity: 7.7482\n",
      "Epoch [2/3], Step [1380/4624], Loss: 2.0730, Perplexity: 7.9487\n",
      "Epoch [2/3], Step [1400/4624], Loss: 2.0742, Perplexity: 7.9583\n",
      "Epoch [2/3], Step [1420/4624], Loss: 2.0714, Perplexity: 7.9356\n",
      "Epoch [2/3], Step [1440/4624], Loss: 2.0003, Perplexity: 7.3910\n",
      "Epoch [2/3], Step [1460/4624], Loss: 2.0503, Perplexity: 7.7699\n",
      "Epoch [2/3], Step [1480/4624], Loss: 2.2748, Perplexity: 9.7261\n",
      "Epoch [2/3], Step [1500/4624], Loss: 2.1310, Perplexity: 8.4230\n",
      "Epoch [2/3], Step [1520/4624], Loss: 4.1180, Perplexity: 61.4386\n",
      "Epoch [2/3], Step [1540/4624], Loss: 2.1156, Perplexity: 8.2947\n",
      "Epoch [2/3], Step [1560/4624], Loss: 2.2403, Perplexity: 9.3966\n",
      "Epoch [2/3], Step [1580/4624], Loss: 2.0422, Perplexity: 7.7073\n",
      "Epoch [2/3], Step [1600/4624], Loss: 2.0709, Perplexity: 7.9321\n",
      "Epoch [2/3], Step [1620/4624], Loss: 2.3977, Perplexity: 10.9979\n",
      "Epoch [2/3], Step [1640/4624], Loss: 3.2457, Perplexity: 25.6792\n",
      "Epoch [2/3], Step [1660/4624], Loss: 2.0564, Perplexity: 7.8175\n",
      "Epoch [2/3], Step [1680/4624], Loss: 2.0283, Perplexity: 7.6013\n",
      "Epoch [2/3], Step [1700/4624], Loss: 1.9799, Perplexity: 7.2423\n",
      "Epoch [2/3], Step [1720/4624], Loss: 2.0233, Perplexity: 7.5632\n",
      "Epoch [2/3], Step [1740/4624], Loss: 2.2204, Perplexity: 9.2112\n",
      "Epoch [2/3], Step [1760/4624], Loss: 2.2099, Perplexity: 9.1149\n",
      "Epoch [2/3], Step [1780/4624], Loss: 3.3017, Perplexity: 27.1595\n",
      "Epoch [2/3], Step [1800/4624], Loss: 1.9808, Perplexity: 7.2484\n",
      "Epoch [2/3], Step [1820/4624], Loss: 1.9651, Perplexity: 7.1355\n",
      "Epoch [2/3], Step [1840/4624], Loss: 2.0984, Perplexity: 8.1532\n",
      "Epoch [2/3], Step [1860/4624], Loss: 2.0491, Perplexity: 7.7611\n",
      "Epoch [2/3], Step [1880/4624], Loss: 2.1422, Perplexity: 8.5178\n",
      "Epoch [2/3], Step [1900/4624], Loss: 1.9788, Perplexity: 7.2342\n",
      "Epoch [2/3], Step [1920/4624], Loss: 2.1869, Perplexity: 8.9072\n",
      "Epoch [2/3], Step [1940/4624], Loss: 2.1210, Perplexity: 8.3396\n",
      "Epoch [2/3], Step [1960/4624], Loss: 2.1303, Perplexity: 8.4175\n",
      "Epoch [2/3], Step [1980/4624], Loss: 2.3637, Perplexity: 10.6303\n",
      "Epoch [2/3], Step [2000/4624], Loss: 2.0409, Perplexity: 7.6977\n",
      "Epoch [2/3], Step [2020/4624], Loss: 1.9919, Perplexity: 7.3298\n",
      "Epoch [2/3], Step [2040/4624], Loss: 2.2137, Perplexity: 9.1494\n",
      "Epoch [2/3], Step [2060/4624], Loss: 2.0316, Perplexity: 7.6261\n",
      "Epoch [2/3], Step [2080/4624], Loss: 1.9778, Perplexity: 7.2270\n",
      "Epoch [2/3], Step [2100/4624], Loss: 2.1033, Perplexity: 8.1930\n",
      "Epoch [2/3], Step [2120/4624], Loss: 2.0920, Perplexity: 8.1014\n",
      "Epoch [2/3], Step [2140/4624], Loss: 2.1023, Perplexity: 8.1850\n",
      "Epoch [2/3], Step [2160/4624], Loss: 2.0315, Perplexity: 7.6257\n",
      "Epoch [2/3], Step [2180/4624], Loss: 1.9922, Perplexity: 7.3316\n",
      "Epoch [2/3], Step [2200/4624], Loss: 1.9817, Perplexity: 7.2548\n",
      "Epoch [2/3], Step [2220/4624], Loss: 2.2917, Perplexity: 9.8919\n",
      "Epoch [2/3], Step [2240/4624], Loss: 2.2921, Perplexity: 9.8958\n",
      "Epoch [2/3], Step [2260/4624], Loss: 2.0934, Perplexity: 8.1125\n",
      "Epoch [2/3], Step [2280/4624], Loss: 1.9700, Perplexity: 7.1707\n",
      "Epoch [2/3], Step [2300/4624], Loss: 1.9783, Perplexity: 7.2306\n",
      "Epoch [2/3], Step [2320/4624], Loss: 2.1670, Perplexity: 8.7325\n",
      "Epoch [2/3], Step [2340/4624], Loss: 2.2468, Perplexity: 9.4570\n",
      "Epoch [2/3], Step [2360/4624], Loss: 2.0074, Perplexity: 7.4441\n",
      "Epoch [2/3], Step [2380/4624], Loss: 2.0778, Perplexity: 7.9868\n",
      "Epoch [2/3], Step [2400/4624], Loss: 2.0520, Perplexity: 7.7838\n",
      "Epoch [2/3], Step [2420/4624], Loss: 2.1042, Perplexity: 8.2007\n",
      "Epoch [2/3], Step [2440/4624], Loss: 2.0214, Perplexity: 7.5489\n",
      "Epoch [2/3], Step [2460/4624], Loss: 2.0289, Perplexity: 7.6055\n",
      "Epoch [2/3], Step [2480/4624], Loss: 2.0293, Perplexity: 7.6085\n",
      "Epoch [2/3], Step [2500/4624], Loss: 1.9113, Perplexity: 6.7619\n",
      "Epoch [2/3], Step [2520/4624], Loss: 2.1325, Perplexity: 8.4359\n",
      "Epoch [2/3], Step [2540/4624], Loss: 2.3194, Perplexity: 10.1697\n",
      "Epoch [2/3], Step [2560/4624], Loss: 2.0974, Perplexity: 8.1449\n",
      "Epoch [2/3], Step [2580/4624], Loss: 2.0134, Perplexity: 7.4884\n",
      "Epoch [2/3], Step [2600/4624], Loss: 1.9495, Perplexity: 7.0252\n",
      "Epoch [2/3], Step [2620/4624], Loss: 1.9778, Perplexity: 7.2271\n",
      "Epoch [2/3], Step [2640/4624], Loss: 2.1599, Perplexity: 8.6700\n",
      "Epoch [2/3], Step [2660/4624], Loss: 2.2610, Perplexity: 9.5928\n",
      "Epoch [2/3], Step [2680/4624], Loss: 2.5179, Perplexity: 12.4020\n",
      "Epoch [2/3], Step [2700/4624], Loss: 2.2493, Perplexity: 9.4815\n",
      "Epoch [2/3], Step [2720/4624], Loss: 2.0983, Perplexity: 8.1526\n",
      "Epoch [2/3], Step [2740/4624], Loss: 1.9146, Perplexity: 6.7839\n",
      "Epoch [2/3], Step [2760/4624], Loss: 2.0512, Perplexity: 7.7773\n",
      "Epoch [2/3], Step [2780/4624], Loss: 2.2958, Perplexity: 9.9328\n",
      "Epoch [2/3], Step [2800/4624], Loss: 2.1080, Perplexity: 8.2319\n",
      "Epoch [2/3], Step [2820/4624], Loss: 2.0051, Perplexity: 7.4272\n",
      "Epoch [2/3], Step [2840/4624], Loss: 2.0196, Perplexity: 7.5355\n",
      "Epoch [2/3], Step [2860/4624], Loss: 2.0543, Perplexity: 7.8011\n",
      "Epoch [2/3], Step [2880/4624], Loss: 1.9406, Perplexity: 6.9626\n",
      "Epoch [2/3], Step [2900/4624], Loss: 2.0946, Perplexity: 8.1226\n",
      "Epoch [2/3], Step [2920/4624], Loss: 1.9893, Perplexity: 7.3103\n",
      "Epoch [2/3], Step [2940/4624], Loss: 2.0768, Perplexity: 7.9793\n",
      "Epoch [2/3], Step [2960/4624], Loss: 2.1418, Perplexity: 8.5151\n",
      "Epoch [2/3], Step [2980/4624], Loss: 2.0180, Perplexity: 7.5233\n",
      "Epoch [2/3], Step [3000/4624], Loss: 2.0252, Perplexity: 7.5775\n",
      "Epoch [2/3], Step [3020/4624], Loss: 1.9567, Perplexity: 7.0761\n",
      "Epoch [2/3], Step [3040/4624], Loss: 2.0909, Perplexity: 8.0920\n",
      "Epoch [2/3], Step [3060/4624], Loss: 1.9201, Perplexity: 6.8217\n",
      "Epoch [2/3], Step [3080/4624], Loss: 2.0073, Perplexity: 7.4435\n",
      "Epoch [2/3], Step [3100/4624], Loss: 2.4557, Perplexity: 11.6549\n",
      "Epoch [2/3], Step [3120/4624], Loss: 1.9953, Perplexity: 7.3545\n",
      "Epoch [2/3], Step [3140/4624], Loss: 2.0071, Perplexity: 7.4419\n",
      "Epoch [2/3], Step [3160/4624], Loss: 2.0112, Perplexity: 7.4723\n",
      "Epoch [2/3], Step [3180/4624], Loss: 1.8925, Perplexity: 6.6360\n",
      "Epoch [2/3], Step [3200/4624], Loss: 1.9911, Perplexity: 7.3236\n",
      "Epoch [2/3], Step [3220/4624], Loss: 2.2411, Perplexity: 9.4039\n",
      "Epoch [2/3], Step [3240/4624], Loss: 2.0022, Perplexity: 7.4055\n",
      "Epoch [2/3], Step [3260/4624], Loss: 1.8711, Perplexity: 6.4957\n",
      "Epoch [2/3], Step [3280/4624], Loss: 2.0746, Perplexity: 7.9615\n",
      "Epoch [2/3], Step [3300/4624], Loss: 2.0928, Perplexity: 8.1078\n",
      "Epoch [2/3], Step [3320/4624], Loss: 2.3428, Perplexity: 10.4105\n",
      "Epoch [2/3], Step [3340/4624], Loss: 1.9942, Perplexity: 7.3466\n",
      "Epoch [2/3], Step [3360/4624], Loss: 2.2556, Perplexity: 9.5406\n",
      "Epoch [2/3], Step [3380/4624], Loss: 1.9448, Perplexity: 6.9925\n",
      "Epoch [2/3], Step [3400/4624], Loss: 1.9196, Perplexity: 6.8184\n",
      "Epoch [2/3], Step [3420/4624], Loss: 2.1970, Perplexity: 8.9978\n",
      "Epoch [2/3], Step [3440/4624], Loss: 2.0272, Perplexity: 7.5927\n",
      "Epoch [2/3], Step [3460/4624], Loss: 2.3086, Perplexity: 10.0602\n",
      "Epoch [2/3], Step [3480/4624], Loss: 1.9804, Perplexity: 7.2454\n",
      "Epoch [2/3], Step [3500/4624], Loss: 1.9570, Perplexity: 7.0778\n",
      "Epoch [2/3], Step [3520/4624], Loss: 1.8567, Perplexity: 6.4026\n",
      "Epoch [2/3], Step [3540/4624], Loss: 2.1404, Perplexity: 8.5030\n",
      "Epoch [2/3], Step [3560/4624], Loss: 1.9957, Perplexity: 7.3576\n",
      "Epoch [2/3], Step [3580/4624], Loss: 2.7572, Perplexity: 15.7556\n",
      "Epoch [2/3], Step [3600/4624], Loss: 2.0440, Perplexity: 7.7215\n",
      "Epoch [2/3], Step [3620/4624], Loss: 2.1591, Perplexity: 8.6637\n",
      "Epoch [2/3], Step [3640/4624], Loss: 2.2463, Perplexity: 9.4525\n",
      "Epoch [2/3], Step [3660/4624], Loss: 1.9662, Perplexity: 7.1437\n",
      "Epoch [2/3], Step [3680/4624], Loss: 2.1245, Perplexity: 8.3689\n",
      "Epoch [2/3], Step [3700/4624], Loss: 2.1527, Perplexity: 8.6080\n",
      "Epoch [2/3], Step [3720/4624], Loss: 2.8690, Perplexity: 17.6200\n",
      "Epoch [2/3], Step [3740/4624], Loss: 2.0767, Perplexity: 7.9783\n",
      "Epoch [2/3], Step [3760/4624], Loss: 1.9806, Perplexity: 7.2474\n",
      "Epoch [2/3], Step [3780/4624], Loss: 1.9681, Perplexity: 7.1571\n",
      "Epoch [2/3], Step [3800/4624], Loss: 1.8682, Perplexity: 6.4767\n",
      "Epoch [2/3], Step [3820/4624], Loss: 1.9834, Perplexity: 7.2676\n",
      "Epoch [2/3], Step [3840/4624], Loss: 2.0100, Perplexity: 7.4632\n",
      "Epoch [2/3], Step [3860/4624], Loss: 2.0475, Perplexity: 7.7482\n",
      "Epoch [2/3], Step [3880/4624], Loss: 1.9868, Perplexity: 7.2924\n",
      "Epoch [2/3], Step [3900/4624], Loss: 2.0400, Perplexity: 7.6904\n",
      "Epoch [2/3], Step [3920/4624], Loss: 1.9979, Perplexity: 7.3736\n",
      "Epoch [2/3], Step [3940/4624], Loss: 2.0515, Perplexity: 7.7796\n",
      "Epoch [2/3], Step [3960/4624], Loss: 2.2419, Perplexity: 9.4107\n",
      "Epoch [2/3], Step [3980/4624], Loss: 2.0667, Perplexity: 7.8988\n",
      "Epoch [2/3], Step [4000/4624], Loss: 2.0548, Perplexity: 7.8057\n",
      "Epoch [2/3], Step [4020/4624], Loss: 1.9396, Perplexity: 6.9563\n",
      "Epoch [2/3], Step [4040/4624], Loss: 2.0025, Perplexity: 7.4077\n",
      "Epoch [2/3], Step [4060/4624], Loss: 1.9412, Perplexity: 6.9670\n",
      "Epoch [2/3], Step [4080/4624], Loss: 2.0797, Perplexity: 8.0018\n",
      "Epoch [2/3], Step [4100/4624], Loss: 1.9689, Perplexity: 7.1626\n",
      "Epoch [2/3], Step [4120/4624], Loss: 1.9627, Perplexity: 7.1182\n",
      "Epoch [2/3], Step [4140/4624], Loss: 2.2270, Perplexity: 9.2721\n",
      "Epoch [2/3], Step [4160/4624], Loss: 1.8597, Perplexity: 6.4220\n",
      "Epoch [2/3], Step [4180/4624], Loss: 2.1099, Perplexity: 8.2470\n",
      "Epoch [2/3], Step [4200/4624], Loss: 1.9724, Perplexity: 7.1876\n",
      "Epoch [2/3], Step [4220/4624], Loss: 2.2326, Perplexity: 9.3242\n",
      "Epoch [2/3], Step [4240/4624], Loss: 1.9101, Perplexity: 6.7535\n",
      "Epoch [2/3], Step [4260/4624], Loss: 1.8979, Perplexity: 6.6721\n",
      "Epoch [2/3], Step [4280/4624], Loss: 1.8302, Perplexity: 6.2353\n",
      "Epoch [2/3], Step [4300/4624], Loss: 1.9436, Perplexity: 6.9835\n",
      "Epoch [2/3], Step [4320/4624], Loss: 2.0366, Perplexity: 7.6641\n",
      "Epoch [2/3], Step [4340/4624], Loss: 1.8907, Perplexity: 6.6239\n",
      "Epoch [2/3], Step [4360/4624], Loss: 1.9985, Perplexity: 7.3777\n",
      "Epoch [2/3], Step [4380/4624], Loss: 1.9551, Perplexity: 7.0645\n",
      "Epoch [2/3], Step [4400/4624], Loss: 2.0451, Perplexity: 7.7298\n",
      "Epoch [2/3], Step [4420/4624], Loss: 1.9207, Perplexity: 6.8257\n",
      "Epoch [2/3], Step [4440/4624], Loss: 2.0688, Perplexity: 7.9151\n",
      "Epoch [2/3], Step [4460/4624], Loss: 1.9696, Perplexity: 7.1677\n",
      "Epoch [2/3], Step [4480/4624], Loss: 1.8815, Perplexity: 6.5631\n",
      "Epoch [2/3], Step [4500/4624], Loss: 1.9144, Perplexity: 6.7831\n",
      "Epoch [2/3], Step [4520/4624], Loss: 1.9062, Perplexity: 6.7273\n",
      "Epoch [2/3], Step [4540/4624], Loss: 2.5281, Perplexity: 12.5297\n",
      "Epoch [2/3], Step [4560/4624], Loss: 2.1558, Perplexity: 8.6344\n",
      "Epoch [2/3], Step [4580/4624], Loss: 1.9660, Perplexity: 7.1422\n",
      "Epoch [2/3], Step [4600/4624], Loss: 2.1913, Perplexity: 8.9472\n",
      "Epoch [2/3], Step [4620/4624], Loss: 2.3700, Perplexity: 10.6976\n",
      "Epoch [3/3], Step [20/4624], Loss: 1.8364, Perplexity: 6.2739\n",
      "Epoch [3/3], Step [40/4624], Loss: 2.2838, Perplexity: 9.8143\n",
      "Epoch [3/3], Step [60/4624], Loss: 1.8564, Perplexity: 6.4005\n",
      "Epoch [3/3], Step [80/4624], Loss: 2.4134, Perplexity: 11.1724\n",
      "Epoch [3/3], Step [100/4624], Loss: 1.9582, Perplexity: 7.0863\n",
      "Epoch [3/3], Step [120/4624], Loss: 2.0110, Perplexity: 7.4709\n",
      "Epoch [3/3], Step [140/4624], Loss: 2.2967, Perplexity: 9.9416\n",
      "Epoch [3/3], Step [160/4624], Loss: 3.4339, Perplexity: 30.9966\n",
      "Epoch [3/3], Step [180/4624], Loss: 1.8788, Perplexity: 6.5454\n",
      "Epoch [3/3], Step [200/4624], Loss: 1.9719, Perplexity: 7.1845\n",
      "Epoch [3/3], Step [220/4624], Loss: 2.0864, Perplexity: 8.0558\n",
      "Epoch [3/3], Step [240/4624], Loss: 1.9782, Perplexity: 7.2301\n",
      "Epoch [3/3], Step [260/4624], Loss: 2.0950, Perplexity: 8.1253\n",
      "Epoch [3/3], Step [280/4624], Loss: 2.1581, Perplexity: 8.6550\n",
      "Epoch [3/3], Step [300/4624], Loss: 1.8867, Perplexity: 6.5975\n",
      "Epoch [3/3], Step [320/4624], Loss: 1.9983, Perplexity: 7.3765\n",
      "Epoch [3/3], Step [340/4624], Loss: 2.0266, Perplexity: 7.5879\n",
      "Epoch [3/3], Step [360/4624], Loss: 2.0275, Perplexity: 7.5950\n",
      "Epoch [3/3], Step [380/4624], Loss: 2.0905, Perplexity: 8.0887\n",
      "Epoch [3/3], Step [400/4624], Loss: 2.1420, Perplexity: 8.5161\n",
      "Epoch [3/3], Step [420/4624], Loss: 2.0787, Perplexity: 7.9939\n",
      "Epoch [3/3], Step [440/4624], Loss: 2.1875, Perplexity: 8.9130\n",
      "Epoch [3/3], Step [460/4624], Loss: 2.0236, Perplexity: 7.5653\n",
      "Epoch [3/3], Step [480/4624], Loss: 1.8319, Perplexity: 6.2458\n",
      "Epoch [3/3], Step [500/4624], Loss: 2.1216, Perplexity: 8.3446\n",
      "Epoch [3/3], Step [520/4624], Loss: 2.0181, Perplexity: 7.5242\n",
      "Epoch [3/3], Step [540/4624], Loss: 1.9904, Perplexity: 7.3182\n",
      "Epoch [3/3], Step [560/4624], Loss: 2.2267, Perplexity: 9.2694\n",
      "Epoch [3/3], Step [580/4624], Loss: 1.8517, Perplexity: 6.3705\n",
      "Epoch [3/3], Step [600/4624], Loss: 1.9865, Perplexity: 7.2898\n",
      "Epoch [3/3], Step [620/4624], Loss: 1.9342, Perplexity: 6.9185\n",
      "Epoch [3/3], Step [640/4624], Loss: 1.8760, Perplexity: 6.5276\n",
      "Epoch [3/3], Step [660/4624], Loss: 2.2836, Perplexity: 9.8123\n",
      "Epoch [3/3], Step [680/4624], Loss: 2.3484, Perplexity: 10.4688\n",
      "Epoch [3/3], Step [700/4624], Loss: 1.9257, Perplexity: 6.8602\n",
      "Epoch [3/3], Step [720/4624], Loss: 1.9837, Perplexity: 7.2697\n",
      "Epoch [3/3], Step [740/4624], Loss: 1.8984, Perplexity: 6.6750\n",
      "Epoch [3/3], Step [760/4624], Loss: 2.6181, Perplexity: 13.7103\n",
      "Epoch [3/3], Step [780/4624], Loss: 1.9933, Perplexity: 7.3399\n",
      "Epoch [3/3], Step [800/4624], Loss: 1.9551, Perplexity: 7.0645\n",
      "Epoch [3/3], Step [820/4624], Loss: 1.9053, Perplexity: 6.7213\n",
      "Epoch [3/3], Step [840/4624], Loss: 1.9536, Perplexity: 7.0544\n",
      "Epoch [3/3], Step [860/4624], Loss: 2.0036, Perplexity: 7.4159\n",
      "Epoch [3/3], Step [880/4624], Loss: 2.6912, Perplexity: 14.7501\n",
      "Epoch [3/3], Step [900/4624], Loss: 1.8444, Perplexity: 6.3246\n",
      "Epoch [3/3], Step [920/4624], Loss: 1.7868, Perplexity: 5.9703\n",
      "Epoch [3/3], Step [940/4624], Loss: 2.0687, Perplexity: 7.9147\n",
      "Epoch [3/3], Step [960/4624], Loss: 2.4124, Perplexity: 11.1606\n",
      "Epoch [3/3], Step [980/4624], Loss: 2.1738, Perplexity: 8.7917\n",
      "Epoch [3/3], Step [1000/4624], Loss: 1.9210, Perplexity: 6.8279\n",
      "Epoch [3/3], Step [1020/4624], Loss: 1.9957, Perplexity: 7.3571\n",
      "Epoch [3/3], Step [1040/4624], Loss: 1.8112, Perplexity: 6.1176\n",
      "Epoch [3/3], Step [1060/4624], Loss: 1.9682, Perplexity: 7.1581\n",
      "Epoch [3/3], Step [1080/4624], Loss: 1.9677, Perplexity: 7.1539\n",
      "Epoch [3/3], Step [1100/4624], Loss: 2.3425, Perplexity: 10.4073\n",
      "Epoch [3/3], Step [1120/4624], Loss: 1.8968, Perplexity: 6.6648\n",
      "Epoch [3/3], Step [1140/4624], Loss: 2.1057, Perplexity: 8.2129\n",
      "Epoch [3/3], Step [1160/4624], Loss: 1.8708, Perplexity: 6.4933\n",
      "Epoch [3/3], Step [1180/4624], Loss: 1.8547, Perplexity: 6.3898\n",
      "Epoch [3/3], Step [1200/4624], Loss: 1.9363, Perplexity: 6.9333\n",
      "Epoch [3/3], Step [1220/4624], Loss: 1.8903, Perplexity: 6.6213\n",
      "Epoch [3/3], Step [1240/4624], Loss: 1.8912, Perplexity: 6.6276\n",
      "Epoch [3/3], Step [1260/4624], Loss: 2.0062, Perplexity: 7.4350\n",
      "Epoch [3/3], Step [1280/4624], Loss: 1.8607, Perplexity: 6.4280\n",
      "Epoch [3/3], Step [1300/4624], Loss: 1.9084, Perplexity: 6.7421\n",
      "Epoch [3/3], Step [1320/4624], Loss: 2.0732, Perplexity: 7.9499\n",
      "Epoch [3/3], Step [1340/4624], Loss: 2.3994, Perplexity: 11.0166\n",
      "Epoch [3/3], Step [1360/4624], Loss: 2.2991, Perplexity: 9.9650\n",
      "Epoch [3/3], Step [1380/4624], Loss: 1.9795, Perplexity: 7.2392\n",
      "Epoch [3/3], Step [1400/4624], Loss: 2.0202, Perplexity: 7.5397\n",
      "Epoch [3/3], Step [1420/4624], Loss: 1.9310, Perplexity: 6.8965\n",
      "Epoch [3/3], Step [1440/4624], Loss: 2.0426, Perplexity: 7.7110\n",
      "Epoch [3/3], Step [1460/4624], Loss: 1.9403, Perplexity: 6.9609\n",
      "Epoch [3/3], Step [1480/4624], Loss: 2.0551, Perplexity: 7.8080\n",
      "Epoch [3/3], Step [1500/4624], Loss: 1.7659, Perplexity: 5.8470\n",
      "Epoch [3/3], Step [1520/4624], Loss: 2.4079, Perplexity: 11.1109\n",
      "Epoch [3/3], Step [1540/4624], Loss: 1.9455, Perplexity: 6.9973\n",
      "Epoch [3/3], Step [1560/4624], Loss: 1.9350, Perplexity: 6.9240\n",
      "Epoch [3/3], Step [1580/4624], Loss: 1.9404, Perplexity: 6.9616\n",
      "Epoch [3/3], Step [1600/4624], Loss: 2.2358, Perplexity: 9.3540\n",
      "Epoch [3/3], Step [1620/4624], Loss: 1.8839, Perplexity: 6.5792\n",
      "Epoch [3/3], Step [1640/4624], Loss: 2.0449, Perplexity: 7.7288\n",
      "Epoch [3/3], Step [1660/4624], Loss: 2.0327, Perplexity: 7.6347\n",
      "Epoch [3/3], Step [1680/4624], Loss: 1.8982, Perplexity: 6.6742\n",
      "Epoch [3/3], Step [1700/4624], Loss: 2.4797, Perplexity: 11.9382\n",
      "Epoch [3/3], Step [1720/4624], Loss: 1.9088, Perplexity: 6.7451\n",
      "Epoch [3/3], Step [1740/4624], Loss: 1.9281, Perplexity: 6.8764\n",
      "Epoch [3/3], Step [1760/4624], Loss: 2.0866, Perplexity: 8.0572\n",
      "Epoch [3/3], Step [1780/4624], Loss: 1.9279, Perplexity: 6.8749\n",
      "Epoch [3/3], Step [1800/4624], Loss: 2.0708, Perplexity: 7.9312\n",
      "Epoch [3/3], Step [1820/4624], Loss: 2.0003, Perplexity: 7.3911\n",
      "Epoch [3/3], Step [1840/4624], Loss: 1.8184, Perplexity: 6.1617\n",
      "Epoch [3/3], Step [1860/4624], Loss: 1.7837, Perplexity: 5.9516\n",
      "Epoch [3/3], Step [1880/4624], Loss: 1.9207, Perplexity: 6.8260\n",
      "Epoch [3/3], Step [1900/4624], Loss: 2.0021, Perplexity: 7.4048\n",
      "Epoch [3/3], Step [1920/4624], Loss: 1.8534, Perplexity: 6.3814\n",
      "Epoch [3/3], Step [1940/4624], Loss: 1.8526, Perplexity: 6.3764\n",
      "Epoch [3/3], Step [1960/4624], Loss: 2.1665, Perplexity: 8.7281\n",
      "Epoch [3/3], Step [1980/4624], Loss: 1.9064, Perplexity: 6.7290\n",
      "Epoch [3/3], Step [2000/4624], Loss: 1.8746, Perplexity: 6.5182\n",
      "Epoch [3/3], Step [2020/4624], Loss: 2.2630, Perplexity: 9.6114\n",
      "Epoch [3/3], Step [2040/4624], Loss: 1.7662, Perplexity: 5.8485\n",
      "Epoch [3/3], Step [2060/4624], Loss: 1.9982, Perplexity: 7.3757\n",
      "Epoch [3/3], Step [2080/4624], Loss: 1.9257, Perplexity: 6.8601\n",
      "Epoch [3/3], Step [2100/4624], Loss: 1.9469, Perplexity: 7.0068\n",
      "Epoch [3/3], Step [2120/4624], Loss: 2.2749, Perplexity: 9.7271\n",
      "Epoch [3/3], Step [2140/4624], Loss: 1.9385, Perplexity: 6.9486\n",
      "Epoch [3/3], Step [2160/4624], Loss: 2.1272, Perplexity: 8.3912\n",
      "Epoch [3/3], Step [2180/4624], Loss: 1.8590, Perplexity: 6.4171\n",
      "Epoch [3/3], Step [2200/4624], Loss: 2.5808, Perplexity: 13.2076\n",
      "Epoch [3/3], Step [2220/4624], Loss: 1.9061, Perplexity: 6.7270\n",
      "Epoch [3/3], Step [2240/4624], Loss: 2.9132, Perplexity: 18.4163\n",
      "Epoch [3/3], Step [2260/4624], Loss: 1.9199, Perplexity: 6.8201\n",
      "Epoch [3/3], Step [2280/4624], Loss: 1.9039, Perplexity: 6.7118\n",
      "Epoch [3/3], Step [2300/4624], Loss: 1.8619, Perplexity: 6.4358\n",
      "Epoch [3/3], Step [2320/4624], Loss: 2.0725, Perplexity: 7.9444\n",
      "Epoch [3/3], Step [2340/4624], Loss: 1.9060, Perplexity: 6.7264\n",
      "Epoch [3/3], Step [2360/4624], Loss: 1.9566, Perplexity: 7.0750\n",
      "Epoch [3/3], Step [2380/4624], Loss: 2.0055, Perplexity: 7.4299\n",
      "Epoch [3/3], Step [2400/4624], Loss: 1.8303, Perplexity: 6.2356\n",
      "Epoch [3/3], Step [2420/4624], Loss: 1.8534, Perplexity: 6.3814\n",
      "Epoch [3/3], Step [2440/4624], Loss: 2.0348, Perplexity: 7.6505\n",
      "Epoch [3/3], Step [2460/4624], Loss: 1.9353, Perplexity: 6.9264\n",
      "Epoch [3/3], Step [2480/4624], Loss: 2.0523, Perplexity: 7.7859\n",
      "Epoch [3/3], Step [2500/4624], Loss: 4.3696, Perplexity: 79.0121\n",
      "Epoch [3/3], Step [2520/4624], Loss: 1.9528, Perplexity: 7.0484\n",
      "Epoch [3/3], Step [2540/4624], Loss: 2.7653, Perplexity: 15.8835\n",
      "Epoch [3/3], Step [2560/4624], Loss: 2.0696, Perplexity: 7.9218\n",
      "Epoch [3/3], Step [2580/4624], Loss: 1.8164, Perplexity: 6.1497\n",
      "Epoch [3/3], Step [2600/4624], Loss: 1.9923, Perplexity: 7.3323\n",
      "Epoch [3/3], Step [2620/4624], Loss: 2.1604, Perplexity: 8.6748\n",
      "Epoch [3/3], Step [2640/4624], Loss: 2.1633, Perplexity: 8.7002\n",
      "Epoch [3/3], Step [2660/4624], Loss: 2.0484, Perplexity: 7.7553\n",
      "Epoch [3/3], Step [2680/4624], Loss: 1.9872, Perplexity: 7.2952\n",
      "Epoch [3/3], Step [2700/4624], Loss: 1.8784, Perplexity: 6.5429\n",
      "Epoch [3/3], Step [2720/4624], Loss: 1.9562, Perplexity: 7.0725\n",
      "Epoch [3/3], Step [2740/4624], Loss: 1.9166, Perplexity: 6.7976\n",
      "Epoch [3/3], Step [2760/4624], Loss: 2.0780, Perplexity: 7.9883\n",
      "Epoch [3/3], Step [2780/4624], Loss: 2.7117, Perplexity: 15.0544\n",
      "Epoch [3/3], Step [2800/4624], Loss: 1.8781, Perplexity: 6.5409\n",
      "Epoch [3/3], Step [2820/4624], Loss: 1.9775, Perplexity: 7.2245\n",
      "Epoch [3/3], Step [2840/4624], Loss: 1.8144, Perplexity: 6.1372\n",
      "Epoch [3/3], Step [2860/4624], Loss: 1.9495, Perplexity: 7.0250\n",
      "Epoch [3/3], Step [2880/4624], Loss: 2.3733, Perplexity: 10.7332\n",
      "Epoch [3/3], Step [2900/4624], Loss: 1.8891, Perplexity: 6.6133\n",
      "Epoch [3/3], Step [2920/4624], Loss: 2.1080, Perplexity: 8.2316\n",
      "Epoch [3/3], Step [2940/4624], Loss: 2.0954, Perplexity: 8.1289\n",
      "Epoch [3/3], Step [2960/4624], Loss: 1.9811, Perplexity: 7.2506\n",
      "Epoch [3/3], Step [2980/4624], Loss: 1.9574, Perplexity: 7.0807\n",
      "Epoch [3/3], Step [3000/4624], Loss: 1.8712, Perplexity: 6.4963\n",
      "Epoch [3/3], Step [3020/4624], Loss: 1.9377, Perplexity: 6.9428\n",
      "Epoch [3/3], Step [3040/4624], Loss: 1.9533, Perplexity: 7.0517\n",
      "Epoch [3/3], Step [3060/4624], Loss: 2.4783, Perplexity: 11.9215\n",
      "Epoch [3/3], Step [3080/4624], Loss: 2.0358, Perplexity: 7.6582\n",
      "Epoch [3/3], Step [3100/4624], Loss: 1.8808, Perplexity: 6.5589\n",
      "Epoch [3/3], Step [3120/4624], Loss: 1.8720, Perplexity: 6.5012\n",
      "Epoch [3/3], Step [3140/4624], Loss: 1.8594, Perplexity: 6.4198\n",
      "Epoch [3/3], Step [3160/4624], Loss: 2.1199, Perplexity: 8.3302\n",
      "Epoch [3/3], Step [3180/4624], Loss: 1.8930, Perplexity: 6.6395\n",
      "Epoch [3/3], Step [3200/4624], Loss: 1.8160, Perplexity: 6.1473\n",
      "Epoch [3/3], Step [3220/4624], Loss: 2.0863, Perplexity: 8.0551\n",
      "Epoch [3/3], Step [3240/4624], Loss: 1.9200, Perplexity: 6.8207\n",
      "Epoch [3/3], Step [3260/4624], Loss: 1.9151, Perplexity: 6.7876\n",
      "Epoch [3/3], Step [3280/4624], Loss: 2.1089, Perplexity: 8.2388\n",
      "Epoch [3/3], Step [3300/4624], Loss: 1.8759, Perplexity: 6.5269\n",
      "Epoch [3/3], Step [3320/4624], Loss: 1.9605, Perplexity: 7.1031\n",
      "Epoch [3/3], Step [3340/4624], Loss: 1.9517, Perplexity: 7.0407\n",
      "Epoch [3/3], Step [3360/4624], Loss: 2.0774, Perplexity: 7.9839\n",
      "Epoch [3/3], Step [3380/4624], Loss: 1.9984, Perplexity: 7.3773\n",
      "Epoch [3/3], Step [3400/4624], Loss: 1.8545, Perplexity: 6.3885\n",
      "Epoch [3/3], Step [3420/4624], Loss: 2.0444, Perplexity: 7.7248\n",
      "Epoch [3/3], Step [3440/4624], Loss: 1.9010, Perplexity: 6.6924\n",
      "Epoch [3/3], Step [3460/4624], Loss: 1.9457, Perplexity: 6.9984\n",
      "Epoch [3/3], Step [3480/4624], Loss: 1.9758, Perplexity: 7.2122\n",
      "Epoch [3/3], Step [3500/4624], Loss: 1.9272, Perplexity: 6.8700\n",
      "Epoch [3/3], Step [3520/4624], Loss: 1.9711, Perplexity: 7.1783\n",
      "Epoch [3/3], Step [3540/4624], Loss: 2.1134, Perplexity: 8.2766\n",
      "Epoch [3/3], Step [3560/4624], Loss: 1.8405, Perplexity: 6.2996\n",
      "Epoch [3/3], Step [3580/4624], Loss: 2.2287, Perplexity: 9.2877\n",
      "Epoch [3/3], Step [3600/4624], Loss: 1.8915, Perplexity: 6.6294\n",
      "Epoch [3/3], Step [3620/4624], Loss: 1.8431, Perplexity: 6.3159\n",
      "Epoch [3/3], Step [3640/4624], Loss: 2.5021, Perplexity: 12.2077\n",
      "Epoch [3/3], Step [3660/4624], Loss: 1.7766, Perplexity: 5.9098\n",
      "Epoch [3/3], Step [3680/4624], Loss: 2.1463, Perplexity: 8.5529\n",
      "Epoch [3/3], Step [3700/4624], Loss: 1.8479, Perplexity: 6.3462\n",
      "Epoch [3/3], Step [3720/4624], Loss: 1.8710, Perplexity: 6.4947\n",
      "Epoch [3/3], Step [3740/4624], Loss: 1.9275, Perplexity: 6.8722\n",
      "Epoch [3/3], Step [3760/4624], Loss: 1.9140, Perplexity: 6.7805\n",
      "Epoch [3/3], Step [3780/4624], Loss: 1.8034, Perplexity: 6.0702\n",
      "Epoch [3/3], Step [3800/4624], Loss: 1.8811, Perplexity: 6.5605\n",
      "Epoch [3/3], Step [3820/4624], Loss: 1.9594, Perplexity: 7.0951\n",
      "Epoch [3/3], Step [3840/4624], Loss: 2.0514, Perplexity: 7.7787\n",
      "Epoch [3/3], Step [3860/4624], Loss: 1.8816, Perplexity: 6.5639\n",
      "Epoch [3/3], Step [3880/4624], Loss: 1.8306, Perplexity: 6.2376\n",
      "Epoch [3/3], Step [3900/4624], Loss: 1.9162, Perplexity: 6.7948\n",
      "Epoch [3/3], Step [3920/4624], Loss: 1.8792, Perplexity: 6.5483\n",
      "Epoch [3/3], Step [3940/4624], Loss: 2.3496, Perplexity: 10.4812\n",
      "Epoch [3/3], Step [3960/4624], Loss: 1.9606, Perplexity: 7.1033\n",
      "Epoch [3/3], Step [3980/4624], Loss: 1.8901, Perplexity: 6.6198\n",
      "Epoch [3/3], Step [4000/4624], Loss: 1.9436, Perplexity: 6.9835\n",
      "Epoch [3/3], Step [4020/4624], Loss: 1.9787, Perplexity: 7.2337\n",
      "Epoch [3/3], Step [4040/4624], Loss: 1.8866, Perplexity: 6.5972\n",
      "Epoch [3/3], Step [4060/4624], Loss: 1.9058, Perplexity: 6.7246\n",
      "Epoch [3/3], Step [4080/4624], Loss: 1.7102, Perplexity: 5.5301\n",
      "Epoch [3/3], Step [4100/4624], Loss: 1.8459, Perplexity: 6.3338\n",
      "Epoch [3/3], Step [4120/4624], Loss: 1.9928, Perplexity: 7.3361\n",
      "Epoch [3/3], Step [4140/4624], Loss: 1.8731, Perplexity: 6.5084\n",
      "Epoch [3/3], Step [4160/4624], Loss: 1.8658, Perplexity: 6.4610\n",
      "Epoch [3/3], Step [4180/4624], Loss: 1.9241, Perplexity: 6.8490\n",
      "Epoch [3/3], Step [4200/4624], Loss: 2.0399, Perplexity: 7.6897\n",
      "Epoch [3/3], Step [4220/4624], Loss: 2.2716, Perplexity: 9.6945\n",
      "Epoch [3/3], Step [4240/4624], Loss: 2.1762, Perplexity: 8.8124\n",
      "Epoch [3/3], Step [4260/4624], Loss: 1.8893, Perplexity: 6.6145\n",
      "Epoch [3/3], Step [4280/4624], Loss: 1.9016, Perplexity: 6.6969\n",
      "Epoch [3/3], Step [4300/4624], Loss: 1.8259, Perplexity: 6.2083\n",
      "Epoch [3/3], Step [4320/4624], Loss: 1.8996, Perplexity: 6.6835\n",
      "Epoch [3/3], Step [4340/4624], Loss: 2.0352, Perplexity: 7.6534\n",
      "Epoch [3/3], Step [4360/4624], Loss: 2.7055, Perplexity: 14.9615\n",
      "Epoch [3/3], Step [4380/4624], Loss: 2.2637, Perplexity: 9.6183\n",
      "Epoch [3/3], Step [4400/4624], Loss: 2.0374, Perplexity: 7.6708\n",
      "Epoch [3/3], Step [4420/4624], Loss: 1.7995, Perplexity: 6.0467\n",
      "Epoch [3/3], Step [4440/4624], Loss: 1.8148, Perplexity: 6.1401\n",
      "Epoch [3/3], Step [4460/4624], Loss: 1.8165, Perplexity: 6.1503\n",
      "Epoch [3/3], Step [4480/4624], Loss: 1.9041, Perplexity: 6.7136\n",
      "Epoch [3/3], Step [4500/4624], Loss: 1.8767, Perplexity: 6.5322\n",
      "Epoch [3/3], Step [4520/4624], Loss: 2.0549, Perplexity: 7.8057\n",
      "Epoch [3/3], Step [4540/4624], Loss: 1.9801, Perplexity: 7.2437\n",
      "Epoch [3/3], Step [4560/4624], Loss: 2.0858, Perplexity: 8.0508\n",
      "Epoch [3/3], Step [4580/4624], Loss: 1.9446, Perplexity: 6.9911\n",
      "Epoch [3/3], Step [4600/4624], Loss: 2.0311, Perplexity: 7.6222\n",
      "Epoch [3/3], Step [4620/4624], Loss: 1.8583, Perplexity: 6.4129\n"
     ]
    }
   ],
   "source": [
    "# Open the training log file.\n",
    "f = open(log_file, \"w\")\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    for i_step in range(1, total_step + 1):\n",
    "\n",
    "        # Randomly sample a caption length, and sample indices with that length.\n",
    "        indices = data_loader.dataset.get_train_indices()\n",
    "        # Create and assign a batch sampler to retrieve a batch with the sampled indices.\n",
    "        new_sampler = data.sampler.SubsetRandomSampler(indices=indices)\n",
    "        data_loader.batch_sampler.sampler = new_sampler\n",
    "\n",
    "        # Obtain the batch.\n",
    "        images, captions = next(iter(data_loader))\n",
    "\n",
    "        # Move batch of images and captions to GPU if CUDA is available.\n",
    "        images = images.to(device)\n",
    "        captions = captions.to(device)\n",
    "\n",
    "        # Zero the gradients.\n",
    "        decoder.zero_grad()\n",
    "        encoder.zero_grad()\n",
    "\n",
    "        # Passing the inputs through the CNN-RNN model\n",
    "        features = encoder(images)\n",
    "        outputs = decoder(features, captions)\n",
    "\n",
    "        # Calculating the batch loss.\n",
    "        loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))\n",
    "\n",
    "        # Backwarding pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Updating the parameters in the optimizer\n",
    "        optimizer.step()\n",
    "\n",
    "        # Getting training statistics\n",
    "        stats = (\n",
    "            f\"Epoch [{epoch}/{num_epochs}], Step [{i_step}/{total_step}], \"\n",
    "            f\"Loss: {loss.item():.4f}, Perplexity: {np.exp(loss.item()):.4f}\"\n",
    "        )\n",
    "\n",
    "        # Print training statistics to file.\n",
    "        f.write(stats + \"\\n\")\n",
    "        f.flush()\n",
    "\n",
    "        # Print training statistics (on different line).\n",
    "        if i_step % print_every == 0:\n",
    "            print(\"\\r\" + stats)\n",
    "\n",
    "    # Save the weights.\n",
    "    if epoch % save_every == 0:\n",
    "        torch.save(\n",
    "            decoder.state_dict(), os.path.join(\"./models\", \"decoder-%d.pkl\" % epoch)\n",
    "        )\n",
    "        torch.save(\n",
    "            encoder.state_dict(), os.path.join(\"./models\", \"encoder-%d.pkl\" % epoch)\n",
    "        )\n",
    "\n",
    "# Close the training log file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Validating the Model using Bleu Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully loaded from vocab.pkl file!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecoderRNN(\n",
       "  (embed): Embedding(11543, 256)\n",
       "  (lstm): LSTM(256, 512, batch_first=True)\n",
       "  (linear): Linear(in_features=512, out_features=11543, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_test = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            (0.485, 0.456, 0.406),  # normalize image for pre-trained model\n",
    "            (0.229, 0.224, 0.225),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#Create the data loader.\n",
    "val_data_loader = val_get_loader(\n",
    "    transform=transform_test, mode=\"valid\", cocoapi_loc=cocoapi_dir\n",
    ")\n",
    "\n",
    "\n",
    "encoder_file = \"encoder-3.pkl\"\n",
    "decoder_file = \"decoder-3.pkl\"\n",
    "\n",
    "# Initialize the encoder and decoder.\n",
    "encoder = EncoderCNN(embed_size)\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "\n",
    "# Moving models to GPU if CUDA is available.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "# Loading the trained weights\n",
    "encoder.load_state_dict(torch.load(os.path.join(\"./models\", encoder_file), weights_only=True))\n",
    "decoder.load_state_dict(torch.load(os.path.join(\"./models\", decoder_file), weights_only=True))\n",
    "\n",
    "encoder.eval()\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f70f44cd09a47dfaffebc131025874e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Abuzar\\\\Image\\\\cocoapi\\\\images\\\\val2017\\\\000000481404.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# infer captions for all images\u001b[39;00m\n\u001b[0;32m      2\u001b[0m pred_result \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mlist\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_data_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\tqdm\\notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[1;32m--> 250\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mC:\\Abuzar\\Image\\Video-Captioning\\data_loader_val.py:190\u001b[0m, in \u001b[0;36mCoCoDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    188\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpaths[index]\n\u001b[0;32m    189\u001b[0m image_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m--> 190\u001b[0m pil_image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    191\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(pil_image)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# return original image and pre-processed image tensor\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\PIL\\Image.py:3431\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3428\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mfspath(fp))\n\u001b[0;32m   3430\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3431\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3432\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3433\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Abuzar\\\\Image\\\\cocoapi\\\\images\\\\val2017\\\\000000481404.jpg'"
     ]
    }
   ],
   "source": [
    "# infer captions for all images\n",
    "pred_result = defaultdict(list)\n",
    "for img_id, img in tqdm(val_data_loader):\n",
    "    img = img.to(device)\n",
    "    with torch.no_grad():\n",
    "        features = encoder(img).unsqueeze(1)\n",
    "        output = decoder.sample(features)\n",
    "    sentence = clean_sentence(output, val_data_loader.dataset.vocab.idx2word)\n",
    "    pred_result[img_id.item()].append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    #os.path.join(cocoapi_dir, \"cocoapi\", \"annotations/captions_val2014.json\"), \"r\"\n",
    "    os.path.join(cocoapi_dir, \"annotations/captions_val2017.json\"), \"r\"\n",
    ") as f:\n",
    "    caption = json.load(f)\n",
    "\n",
    "valid_annot = caption[\"annotations\"]\n",
    "valid_result = defaultdict(list)\n",
    "for i in valid_annot:\n",
    "    valid_result[i[\"image_id\"]].append(i[\"caption\"].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a black honda motorcycle parked in front of a garage.',\n",
       "  'a honda motorcycle parked in a grass driveway',\n",
       "  'a black honda motorcycle with a dark burgundy seat.',\n",
       "  'ma motorcycle parked on the gravel in front of a garage',\n",
       "  'a motorcycle with its brake extended standing outside'],\n",
       " ['an office cubicle with four different types of computers.',\n",
       "  'the home office space seems to be very cluttered.',\n",
       "  'an office with desk computer and chair and laptop.',\n",
       "  'office setting with a lot of computer screens.',\n",
       "  'a desk and chair in an office cubicle.'],\n",
       " ['a small closed toilet in a cramped space.',\n",
       "  'a tan toilet and sink combination in a small room.',\n",
       "  'this is an advanced toilet with a sink and control panel.',\n",
       "  'a close-up picture of a toilet with a fountain.',\n",
       "  'off white toilet with a faucet and controls. ']]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(valid_result.values())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[' a kitchen with a stove , refrigerator , andsink .'],\n",
       " [' a cake that is sitting on a table .'],\n",
       " [' a room with a desk , a chair , a bookshelf , and a television .']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pred_result.values())[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18904339403329923"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_score(true_sentences=valid_result, predicted_sentences=pred_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a bad bleu score with only 3 epochs!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
